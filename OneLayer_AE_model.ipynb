{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542a3f68-f019-41b6-a2c9-1070807ebda9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementation of an Autoencoder (AE)\n",
    "#### based on PyTorch tutorial https://pytorch.org/tutorials/beginner/basics/intro.html and https://www.cs.toronto.edu/~lczhang/360/lec/w05/autoencoder.html\n",
    "## Simple linear AE with one layer into hidden (latent) space 748 -> 512 -> 10 and back 10 -> 512 -> 748\n",
    "\n",
    "#### Build for MINST datasets\n",
    "\n",
    "###### ***For sc-RNAseq:*** fix enable cuda/GPU (only needed if CPU is to slow), try different optimiser, check for loss function, trying learning rates, nn.ReLU() function may not be the best, checking for overfitting by plotting loss of model and training data, Batch size has to be optimised: https://arxiv.org/abs/1609.04836 , https://arxiv.org/abs/1703.04933 . Maybe we should try a program like https://opendatascience.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler/ for that on a later stage for performance (not sure if the data will be to large in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c170cac6-0e7e-4c2c-98ed-c26c1c7b2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544b516d-aa5f-4481-b7a0-d73f2f9f8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "mnist_data = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=mnist_data,batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(dataset=mnist_data,batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd006b3-bf5d-4077-be2d-789f3cd15016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   ### needed if Nvidia GPU is available and wanted to use the GPU\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ca0269-3957-4123-87d5-6ca4a8daf9a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39e5f45-c408-44e4-97bb-fdb582f3b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=784, bias=True)\n",
      "    (3): Sigmoid()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### Building the neural network structure ####\n",
    "dim_encoder_decoder = 28 * 28\n",
    "\n",
    "class linear_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear_AE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(             # sequential operation of the following code:\n",
    "            nn.Linear(dim_encoder_decoder, 512),  #### data into the neural network layer (28*28 pixel -> 512 nodes)\n",
    "            nn.ReLU(),                            #### ReLU(x) = (x)^(+) = max(0,x) \n",
    "            nn.Linear(512, 10),                   #### layer into the hidden layer / latent space (512 -> 10 nodes / latent vector)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(             # sequential operation of the following code:\n",
    "            nn.Linear(10, 512),                   #### decoding laten layer (10 -> 512 nodes)\n",
    "            nn.ReLU(),                            #### \n",
    "            nn.Linear(512, dim_encoder_decoder),  #### reconstruction of image (512 -> 748)\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):                         # exicute the endcoder and decoder defined in __init__(self)\n",
    "        endoded = self.encoder(x) \n",
    "        decoded = self.decoder(endoded) \n",
    "        return decoded\n",
    "        \n",
    "model = linear_AE()  #.to(device) #### this is needed for cuda\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c03c64-62cb-4f52-a5a0-4ac0231c598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss ###CrossEntropyLoss()               ### nn.MSELoss (Mean Square Error) for regression tasks\n",
    "\n",
    "learning_rate = 1e-3                          ### how much the parameter gets updated\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-3, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11f50ed-17ba-402f-9f5b-55ec5d931013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1, Loss:0.0261 ; Train Loss:0.0191\n",
      "Epoch:2, Loss:0.0168 ; Train Loss:0.0186\n",
      "Epoch:3, Loss:0.0172 ; Train Loss:0.0188\n",
      "Epoch:4, Loss:0.0174 ; Train Loss:0.0197\n",
      "Epoch:5, Loss:0.0167 ; Train Loss:0.0172\n",
      "Epoch:6, Loss:0.0202 ; Train Loss:0.0175\n",
      "Epoch:7, Loss:0.0185 ; Train Loss:0.0144\n",
      "Epoch:8, Loss:0.0160 ; Train Loss:0.0161\n",
      "Epoch:9, Loss:0.0160 ; Train Loss:0.0191\n",
      "Epoch:10, Loss:0.0171 ; Train Loss:0.0139\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "outputs = []\n",
    "torch.manual_seed(42)\n",
    "for epoch in range(num_epochs):\n",
    "    for (X, label) in train_dataloader:\n",
    "        X = X.reshape(-1, 28*28)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, X)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch:{epoch+1}, Loss:{loss.item():.4f}', end=\"\")\n",
    "    outputs.append((epoch, X, pred))\n",
    "    \n",
    "    for (X_test, label) in test_dataloader:\n",
    "        X_test = X_test.reshape(-1, 28*28)\n",
    "        pred_test = model(X_test)\n",
    "        loss_test = loss_fn(pred_test, X_test)\n",
    "    print(f' ; Train Loss:{loss_test.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792f677-47af-4f18-9087-f70ba8bc1cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815aa5fd-7d67-4a59-85ae-87461a6286e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_oneLayer_AE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0b5deda-173d-4321-9007-250312d6235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_oneLayer_AE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0db74de5-1236-4913-8b50-2ae3231bb5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_AE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=10, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=784, bias=True)\n",
       "    (3): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c53c9d-bca2-463a-9421-59eaae65f69c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba73a4-0d50-461f-b2cc-3818732f6dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82118d28-0f09-442f-ba03-ed70af927dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163d9b4-bcbd-4c1f-9eaa-04f26f95f1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c0ea10-1d04-4504-b68f-7485471ccebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989b59de-8188-4667-a727-cec03d177a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
