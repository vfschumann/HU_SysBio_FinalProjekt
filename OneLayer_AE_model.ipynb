{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "542a3f68-f019-41b6-a2c9-1070807ebda9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Implementation of a Autoencoder (AE)\n",
    "#### based on PyTorch tutorial (https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "## Simple AE with one layer into latent space 748 -> 10\n",
    "##### I hope it also does it backwards (at least it works, but other implementations explicitly specify the backward layer and this one does not (in NeuralNetwork_AE)).\n",
    "#### Build for MINST datasets\n",
    "\n",
    "###### ***For sc-RNAseq:*** fix enable cuda/GPU (only needed if CPU is to slow), try different optimiser, check for loss function, trying learning rates, nn.ReLU() function may not be the best, checking for overfitting by plotting loss of model and training data, Batch size has to be optimised: https://arxiv.org/abs/1609.04836 , https://arxiv.org/abs/1703.04933 . Maybe we should try a program like https://opendatascience.com/optimizing-pytorch-performance-batch-size-with-pytorch-profiler/ for that on a later stage for performance (not sure if the data will be to large in the future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c170cac6-0e7e-4c2c-98ed-c26c1c7b2ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "544b516d-aa5f-4481-b7a0-d73f2f9f8657",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "training_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.MNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd006b3-bf5d-4077-be2d-789f3cd15016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c39e5f45-c408-44e4-97bb-fdb582f3b34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork_AE(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class NeuralNetwork_AE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork_AE, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork_AE() #.to(device) #### this is needed for cuda\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c03c64-62cb-4f52-a5a0-4ac0231c598e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5912a895-8d3f-4fc1-a5ff-4b0edbcab99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-4\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69467eb8-c0f8-4ecd-a3ac-8cc4908e1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function:\n",
    "    # nn.MSELoss (Mean Square Error) for regression tasks\n",
    "    # nn.NLLLoss (Negative Log Likelihood) for classification\n",
    "    # nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss\n",
    "\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0f054d0-915f-422d-a4ee-6141862765b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.317503  [    0/60000]\n",
      "loss: 0.395707  [ 6400/60000]\n",
      "loss: 0.263923  [12800/60000]\n",
      "loss: 0.332832  [19200/60000]\n",
      "loss: 0.214908  [25600/60000]\n",
      "loss: 0.307582  [32000/60000]\n",
      "loss: 0.135500  [38400/60000]\n",
      "loss: 0.330453  [44800/60000]\n",
      "loss: 0.257580  [51200/60000]\n",
      "loss: 0.294584  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 94.4%, Avg loss: 0.185234 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.118693  [    0/60000]\n",
      "loss: 0.191264  [ 6400/60000]\n",
      "loss: 0.099930  [12800/60000]\n",
      "loss: 0.192193  [19200/60000]\n",
      "loss: 0.140712  [25600/60000]\n",
      "loss: 0.218253  [32000/60000]\n",
      "loss: 0.057894  [38400/60000]\n",
      "loss: 0.227659  [44800/60000]\n",
      "loss: 0.180948  [51200/60000]\n",
      "loss: 0.206923  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.0%, Avg loss: 0.128071 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.076911  [    0/60000]\n",
      "loss: 0.126406  [ 6400/60000]\n",
      "loss: 0.077345  [12800/60000]\n",
      "loss: 0.097515  [19200/60000]\n",
      "loss: 0.092595  [25600/60000]\n",
      "loss: 0.142932  [32000/60000]\n",
      "loss: 0.038016  [38400/60000]\n",
      "loss: 0.171495  [44800/60000]\n",
      "loss: 0.131590  [51200/60000]\n",
      "loss: 0.160765  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 96.7%, Avg loss: 0.103465 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.053798  [    0/60000]\n",
      "loss: 0.085562  [ 6400/60000]\n",
      "loss: 0.064031  [12800/60000]\n",
      "loss: 0.053148  [19200/60000]\n",
      "loss: 0.062602  [25600/60000]\n",
      "loss: 0.107095  [32000/60000]\n",
      "loss: 0.027720  [38400/60000]\n",
      "loss: 0.120687  [44800/60000]\n",
      "loss: 0.092770  [51200/60000]\n",
      "loss: 0.117290  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.1%, Avg loss: 0.089958 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.036259  [    0/60000]\n",
      "loss: 0.056629  [ 6400/60000]\n",
      "loss: 0.051358  [12800/60000]\n",
      "loss: 0.037492  [19200/60000]\n",
      "loss: 0.043112  [25600/60000]\n",
      "loss: 0.086742  [32000/60000]\n",
      "loss: 0.021211  [38400/60000]\n",
      "loss: 0.080553  [44800/60000]\n",
      "loss: 0.074210  [51200/60000]\n",
      "loss: 0.082287  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 97.4%, Avg loss: 0.081194 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815aa5fd-7d67-4a59-85ae-87461a6286e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_oneLayer_AE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b5deda-173d-4321-9007-250312d6235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model_oneLayer_AE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0db74de5-1236-4913-8b50-2ae3231bb5b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork_AE(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
